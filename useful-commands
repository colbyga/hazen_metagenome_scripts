#######
# using awk
#######
# looking for rows with a second field value greater than 1000
# {print ;} print entire line
awk '$2 > 1000' filename
awk '$4 > 49  {print ;}' collections-refined.txt
awk '$4 > 90  {print ;}' collections-refined.txt | wc -l  # insane quality bins
awk '$4 > 49 &&  $5 > 10 {print ;}' collections-refined.txt | wc -l  # Good bins but contaminated
awk '$5 > 10 {print ;}' collections-refined.txt | wc -l  


awk '{print $13}' qa.out
awk '$13 > 90  {print ;}' qa.out | wc -l  # insane quality bins
awk '$13 > 49 &&  $14 > 10 {print ;}' qa.out | wc -l  # Good bins but contaminated
awk '$13 > 49 &&  $14 > 10 {print ;}' qa.out | awk '{print $1}' # oh look all the contaminated bin names that need work 
awk '$13 > 49 &&  $14 > 10 {print ;}' qa.out | awk '{print $13 "\t" $14}' 
awk '$13 > 49 &&  $14 < 10 {print ;}' qa.out > qa_goodbins.out
awk '$13 > 90 &&  $14 > 10 {print ;}' qa.out | wc -l  # Good bins but contaminated
awk '$13 > 70 &&  $14 > 10 {print ;}' qa.out | wc -l  # Good bins but contaminated



#print specific field
awk '{print $1}' collections-refined-over-49.txt > bins-over-49.txt

######
# using sed 
######
sed -i -e 's/few/asd/g' hello.txt
sed 's/hello/bonjour/' greetings.txt
#using ; as a separator
sed 's;Bin_;$BINS/Bin_;' bins-over-49.txt > bins-over-49.txt

tr '\n' ' ' < bins-over-49.txt > bins-over-49-space.txt


############
#  bringing it together
############
awk '$13 > 49 &&  $14 < 10 {print ;}' qa.out | awk '{print $1}' | sed 's/-contigs/-contigs.fa/g'
awk '$13 > 49 &&  $14 < 10 {print ;}' qa.out | awk '{print $1}' | sed 's/-contigs//g' > goodbins.names

while read p; do
  echo "$p"
done <goodbins.names

while read p; do
  cp -s /global/scratch/hpc3565/output_anvio5_1/SAMPLES-SUMMARY-concoct-checkm/bin_by_bin/$p/$p-contigs.fa /global/scratch/hpc3565//output_anvio5_1/SAMPLES-SUMMARY-concoct-checkm/good_bins
done < goodbins.names

cp -s

######
# using grep 
######
# grep in reverse -v is reverse -w is whole word -i case insensitive -E allows for regrex
grep -vwiE "(superfamily|panther|pirsf)" temp-func-matrix.tsv > filename.tsv
grep -vwE "(cat|rat)" sourcefile > destinationfile


#bash loop
for filename in $(ls *.hmm); do  echo $pwd$filename >> hmm-list.txt; done;


rerunning RGI that didn't run
seq 2 878 > all-errs.txt
cat all-errs.txt | while read f; do echo rgi_1832827_$f.err; done > all-list-of-err.txt
# finding the difference between two files
grep -v -f list-of-err.txt all-list-of-err.txt
#786 files and should be 878
sed 's/rgi_1832827_//' ah-whats-missing.txt > ah-whats-missing2.txt
sed 's/.err//' ah-whats-missing2.txt > ah-whats-missing3.txt
tr '\n' ',' < ah-whats-missing3.txt
ls rgi_1834603* | wc -l #should be 92!


repeating the second time!
sed 's/rgi_1832827_//' list-slurm-errs.txt > list-slurm-errs-2.txt 
sed 's/rgi_1834603_//' list-slurm-errs-2.txt > list-slurm-errs-3.txt  
grep -v -fxF list-slurm-errs-3.txt all-list-of-err.txt
# below is the golden pattern match
grep -vFwf list-slurm-errs.txt all-list-of-err.txt > matches.txt

#grep -Fwfv all-list-of-err.txt list-slurm-errs.txt
#while read i; do grep "$i" fileB; done < fileA


# now for minpath
repeating the second time!
ls *err > all-slurm-errs.txt
sed 's/minpath_1838520_//' all-slurm-errs.txt > all-slurm-errs2.txt
seq 2 878 > all-errs.txt
cat all-errs.txt | while read f; do echo minpath_$f.err; done > all-list-of-err.txt

grep -v -fxF list-slurm-errs-3.txt all-list-of-err.txt
# below is the golden pattern match
grep -vFwf all-slurm-errs2.txt all-list-of-err.txt > matches.txt
sed 's/.err//g' matches.txt > a-rerun.txt
tr '\n' ',' < a-rerun.txt

###########
# extracting only goodbins from the anvio bins_summary.txt
###########
grep -vFwf goodbins.names bins_summary.txt  ### output 570 lines 
grep -Fwf goodbins.names bins_summary.txt   ### output 308 lines
# goodbin abundance



##################
#Compressing files
##################
tar -czvf archive.tar.gz stuff
tar -cjvf archive.tar.bz2 stuff

#working with compressed files 
#extracting a specific file from a tar compressed file 
tar -zxvf <tar filename> <file you want to extract> ### if its tar.gz
tar -jxvf output_anvio5_1.tar.bz2 --strip-components=4 global/scratch/hpc3565/output_anvio5_1/contigs.db -C /Users/grahamcolby/Documents/anvio_refining-post-checkm
tar -jxvf output_anvio5_1.tar.bz2 --strip-components=4 global/scratch/hpc3565/output_anvio5_1/SAMPLES-MERGED -C /Users/grahamcolby/Documents/anvio_refining-post-checkm
tar -jxvf output_anvio5_1.tar.bz2 --strip-components=4 global/scratch/hpc3565/output_anvio5_1/SAMPLES-SUMMARY-concoct


list files
tar -jtvf archive.tar.bz2
tar --bzip2 --list --verbose --file=archive.tar

############
# looking at raw data files
############
# number of reads in fastq.gc file 
zcat my.fastq.gz | echo $((`wc -l`/4))
#or 
cat my.sam | grep -v '^ *@' | wc -l


#count lines in fasta file 
grep -c "^>" file.fa

